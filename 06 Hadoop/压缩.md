# 压缩

**来自：hadoop权威指南第四版压缩部分**

文件压缩的两个好处:

	减少储存文件所需要的磁盘空间
	加速数据在网络和磁盘上的传输
	
hadoop常见的压缩格式：

![compress01](https://s1.ax1x.com/2020/07/13/UtiJBt.png)

	（1）gzip文件格式只是在DEFLATE格式上增加了文件头和文件尾。
	（2）只有bzip2文件能被切分[指从任意位置开始读取数据的能力]。
	（3）如果LZO文件在预处理中被索引了，那么也是可以被切分的。
	（4）在选择压缩算法时，要统一考虑时间和空间的权衡。解压缩速度快，那么节省的空间会变少。

LZO索引创建：[https://blog.csdn.net/dxqlb1001/article/details/88560472?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control](https://blog.csdn.net/dxqlb1001/article/details/88560472?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control)

上述表中的所有压缩工具都提供9个不同的选项来控制压缩，其中:
		
	-1为优化压缩速度
	-9为优化压缩空间
	%gzip -1 file

```	
[root@zgg ~]# ls
wc.txt
[root@zgg ~]# gzip -1 wc.txt 
[root@zgg ~]# ls
wc.txt.gz
```

## 一、Codec

Codec 表示一种压缩-解压缩算法，是 CompressionCodec 接口的实现。

![compress02](https://s1.ax1x.com/2020/07/13/UtEGRS.png)

其中，LZO需要从 `https://github.com/kevinweil/hadoop-lzo` 下载。

### 1、通过CompressionCodec对数据流进行压缩和解压缩

CompressionCodec包含两个函数 可以轻松用于压缩和解压缩数据

	createOutputStream(OutputStream out)：在底层数据流中，对需要以 压缩 格式写入，但在此之前尚未压缩的数据，新建一个CompressionOutputStream对象


	createInputStream(InputStream in)：对输入数据流中读取的数据进行 解压缩 的时候，
		则调用获取CompressionInputStream，通过该方法从底层数据里读取解压缩后的数据

**压缩从标准输入读取的数据,并写到标准输出**

```java

package hadoopbase.compress;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.io.IOUtils;
import org.apache.hadoop.io.compress.CompressionCodec;
import org.apache.hadoop.io.compress.CompressionOutputStream;
import org.apache.hadoop.util.ReflectionUtils;
import org.apache.log4j.BasicConfigurator;

import java.io.IOException;
//出错
public class StreamCompressor {
    public static void main(String[] args) throws ClassNotFoundException, IOException {
        BasicConfigurator.configure();

        String codecClassname = args[0];
        Class<?> codecClass = Class.forName(codecClassname);
        Configuration conf = new Configuration();
        CompressionCodec codec = (CompressionCodec) ReflectionUtils.newInstance(codecClass, conf);

        CompressionOutputStream out = codec.createOutputStream(System.out);
        // out 从 System.in 取到数据，压缩后，输出到  System.out
        IOUtils.copyBytes(System.in, out, 4096, false);
        out.finish();
    }
}

```

编译后，压缩从标准输入读取的数据，并写到标准输出，通过管道传递给gunzip，显示压缩内容:

```sh
[root@zgg jar]# echo "Test" | hadoop jar sc.jar hadoop.compress.StreamCompressor  org.apache.hadoop.io.compress.GzipCodec | gunzip  
2020-12-20 15:11:17,331 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2020-12-20 15:11:17,387 INFO compress.CodecPool: Got brand-new compressor [.gz]

gzip: stdin: not in gzip format
```

### 2、通过CompressionCodecFactory推断CompressionCodec

CompressionCodecFactory 的 getCodec() 方法可以根据文件名后缀，匹配到该文件的相关的压缩-解压缩算法。

```java
package hadoopbase.compress;

import java.io.InputStream;
import java.io.OutputStream;
import java.net.URI;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IOUtils;
import org.apache.hadoop.io.compress.CompressionCodec;
import org.apache.hadoop.io.compress.CompressionCodecFactory;

//需求：根据文件扩展名选取codec，解压缩文件
public class FileDecompressor {
    public static void main(String[] args) throws Exception {
        String uri = args[0];
        Configuration conf = new Configuration();
        FileSystem fs = FileSystem.get(URI.create(uri), conf);

        Path inputPath = new Path(uri);
        CompressionCodecFactory factory = new CompressionCodecFactory(conf);
        CompressionCodec codec = factory.getCodec(inputPath);
        if (codec == null) {
            System.err.println("No codec found for " + uri);
            System.exit(1);
        }

        //取掉后缀后，为输出uri
        String outputUri =
                CompressionCodecFactory.removeSuffix(uri, codec.getDefaultExtension());

        InputStream in = null;
        OutputStream out = null;
        try {
            in = codec.createInputStream(fs.open(inputPath));
            out = fs.create(new Path(outputUri));
            IOUtils.copyBytes(in, out, conf);
        } finally {
            IOUtils.closeStream(in);
            IOUtils.closeStream(out);
        }
    }
}

```

- 在idea中将文件打包成jar包，导入虚拟机。
- 上传wc.txt.gz文件到hdfs
- 执行`hadoop jar JavaCode.jar hadoopbase.compress.FileDecompressor /in/wc.txt.gz`
- 完成后会看到wc.txt文件。

![compress03](https://s1.ax1x.com/2020/07/13/UtmM6S.png)

CompressionCodecFactory 会加载图二中除LZO以外的所有Codec，也会加载配置属性列表中的所有Codec。

属性名|类型|默认值|描述
---|:---:|---|---
io.compression.codec|逗号分隔的类名|空|用于压缩解压缩的额外的CompressionCodec类的列表

### 3、原生类库

相比Java实现，使用原生(native)类库来实现压缩-解压缩，会减少压缩时间和解压缩时间。

![compress04](https://s1.ax1x.com/2020/07/15/Uwp5Pf.png)

通过 `io.native.lib.available = True` 来启用这个属性。

可以在 `/etc/hadoop` 下的hadoop脚本，通过Java系统的 `java.library.path` 属性来指定原生(native)类库。
也可以在应用程序内部指定。

### 4、CodecPool

当使用了原生类库，且程序中需要 **执行大量的压缩和解压缩操作**，可以使用CodecPool。

因为CodecPool支持反复使用压缩和解压缩操作，以分摊创建对象的开销。

```java
package hadoopbase.compress;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.io.IOUtils;
import org.apache.hadoop.io.compress.*;
import org.apache.hadoop.util.ReflectionUtils;

/*
 * 使用压缩池对读取自标准输入的数据进行压缩,然后将其写到标准输出
 *
 */

public class PooledStreamCompressor {
    public static void main(String[] args) throws Exception {
        String codecClassname = args[0];
        Class<?> codecClass = Class.forName(codecClassname);

        Configuration conf = new Configuration();
        CompressionCodec codec = (CompressionCodec)
                ReflectionUtils.newInstance(codecClass, conf);

        Compressor compressor = null;
        try {
		    //对于指定的CompressionCodec，从池中获取一个压缩器
            compressor = CodecPool.getCompressor(codec);
            CompressionOutputStream out =
                    codec.createOutputStream(System.out, compressor);
            IOUtils.copyBytes(System.in, out, 4096, false);
            out.finish();
            //通过finally数据块，可以在不同数据流间来回复制数据，即使出现IOException，也能保证compressor返回到池中
            } finally {
            CodecPool.returnCompressor(compressor);
        }
    }
}

```

## 二、压缩和输入分片

假设文件A被压缩后的大小为1GB，HDFS将其切分为8个block(一个block128MB)。

如果文件A采用gzip压缩，而gzip是不支持切分的，无法实现从压缩数据流任意
位置读取数据，所以系统无法处理block。

如果文件A采用LZO压缩,可以通过在预处理阶段使用索引工具，构建切分点索引，
实现切分，从而系统能正确处理block。

bzip2提供不同block间的同步标识，所以也是支持切分的。

说明:

	存储在HDFS的每个块都不是完整的文件，
    我们可以把一个完整的文件认为是具有首尾标识的，
    因为被切分了，所以每个数据块有些有头标示，有些有尾标示，有些头尾标示都没有，
    所以就不能多任务来并行对这个文件进行处理。

### 1、应该使用哪种压缩格式?

使用哪种压缩格式与待处理的文件大小、格式和所使用的工具相关。大致按照效率从高到低排列:

- 使用容器文件格式，例如 **顺序文件，REFile或者Avro数据文件**，这些格式同时支持
压缩和切分。通常最好与一个快速压缩工具联合使用，例如: **LZO,LZ4或者Snappy**。

- 使用 **支持切分的压缩格式**，例如 **bzip2**，或者使用通过索引实现切分的
压缩格式，例如: **LZO**。

- 在应用中将文件切分成块，并使用任意一种压缩格式为每个数据块建立压缩文件
(不论它是否支持切分)。这时，需要合理选择数据块大小，以确保压缩后数据块的大
小近似于HDFS块的大小。

- 储存未经压缩的文件。

对于大文件来说，**不要使用不支持切分整个文件的压缩格式**，因为会失去数据的本地特性，
进而造成MapReduce应用效率低下。

## 三、在MapReduce中使用压缩

### 1、对map任务输出进行压缩

map任务的输出需要写到磁盘并通过网络传输到reducer节点，所以如果使用LZO、LZ4
或者Snappy这样的快速压缩方式，是可以获取性能提升的。

`mapred-default.xml` 中的相关属性:

属性|默认值|描述
---|:---|:---
mapreduce.map.output.compress|false|是否对map任务的输出进行压缩
mapreduce.map.output.compress.codec|org.apache.hadoop.io.compress.DefaultCodec|选择的压缩算法

如果要压缩，就要在 `mapred-default.xml` 文件中先启动(设为true)，
然后再指定压缩算法。

也可以在main函数中设置属性。

```java
Configuration conf = new Configuration();
conf.setBoolean("mapreduce.map.output.compress", true);
conf.setClass("mapreduce.map.output.compress.codec", GzipCodec.class, CompressionCodec.class);
```

旧api中:

```java
conf.setCompressMapOutput(true);
conf.setMapOutputCompressorClass(GzipCodec.class);
```

### 2、对reduce任务输出进行压缩

`mapred-default.xml` 中的相关属性:

属性|默认值|描述
---|:---|:---
mapreduce.output.fileoutputformat.compress|false|job的输出要不要压缩
mapreduce.output.fileoutputformat.compress.codec|org.apache.hadoop.io.compress.DefaultCodec|选择的压缩算法
mapreduce.output.fileoutputformat.compress.type|RECORD|SequenceFiles文件输出 可以使用的压缩类型:NONE\RECORD\BLOCK

说明:

	`mapreduce.output.fileoutputformat.compress.codec` 属性来控制使用压缩格式。
	默认值为RECORD，即对每一条记录进行压缩;
    如果将其改为BLOCK，将针对一组记录进行压缩,压缩效率更高.
	
	在SequenceFileOutputFormat类中还有一个静态方法 `putCompressionType()` 可用来便捷地设置该属性。

如果要压缩，就要在 `mapred-default.xml` 文件中先启动(设为true)，然后再指定压缩算法。

也可以在main函数中设置属性。

## 四、示例

MaxTemperatureMapper和MaxTemperatureReducer见 [JavaCode](https://github.com/ZGG2016/JavaCode/tree/master/src)

### 1、对map任务输出进行压缩

```java
public class MaxTemperatureWithMapOutputCompression {

    private static final String INPUT_PATH = "hdfs://zgg:9000/in/sample.txt";
    private static final String OUTPUT_PATH = "hdfs://zgg:9000/out/mtmc";

    public static void main(String[] args) throws Exception {

        BasicConfigurator.configure();
        Configuration conf = new Configuration();
        conf.setBoolean(Job.MAP_OUTPUT_COMPRESS, true);
        conf.setClass(Job.MAP_OUTPUT_COMPRESS_CODEC, BZip2Codec.class,
                CompressionCodec.class);

        FileSystem fs = FileSystem.get(new URI(INPUT_PATH), conf);
        Path outPath = new Path(OUTPUT_PATH);
        if(fs.exists(outPath)){
            fs.delete(outPath,true);
        }

        Job job = Job.getInstance(conf);
        job.setJarByClass(MaxTemperatureWithMapOutputCompression.class);

        job.setMapperClass(MaxTemperatureMapper.class);

        job.setCombinerClass(MaxTemperatureReducer.class);

        job.setReducerClass(MaxTemperatureReducer.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);

        FileInputFormat.addInputPath(job, new Path(INPUT_PATH));
        FileOutputFormat.setOutputPath(job, new Path(OUTPUT_PATH));

        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}
```

### 2、对reduce任务输出进行压缩

```java
package hadoopbase.compress;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.compress.BZip2Codec;
import org.apache.hadoop.io.compress.GzipCodec;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.log4j.BasicConfigurator;

import java.net.URI;

public class MaxTemperatureWithCompression {

    private static final String INPUT_PATH = "hdfs://zgg:9000/in/sample.txt";
    private static final String OUTPUT_PATH = "hdfs://zgg:9000/out/mtc";

    public static void main(String[] args) throws Exception {

        BasicConfigurator.configure();
        Configuration conf = new Configuration();

        FileSystem fs = FileSystem.get(new URI(INPUT_PATH), conf);
        Path outPath = new Path(OUTPUT_PATH);
        if(fs.exists(outPath)){
            fs.delete(outPath,true);
        }

        Job job = Job.getInstance(conf);
        job.setJarByClass(MaxTemperatureWithCompression.class);

        FileInputFormat.addInputPath(job, new Path(INPUT_PATH));
        FileOutputFormat.setOutputPath(job, new Path(OUTPUT_PATH));

        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);

        FileOutputFormat.setCompressOutput(job, true);
        FileOutputFormat.setOutputCompressorClass(job, BZip2Codec.class);

        job.setMapperClass(MaxTemperatureWithMapOutputCompression.MaxTemperatureMapper.class);
        job.setCombinerClass(MaxTemperatureWithMapOutputCompression.MaxTemperatureReducer.class);
        job.setReducerClass(MaxTemperatureWithMapOutputCompression.MaxTemperatureReducer.class);

        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}

```

输出:

	[root@zgg ~]# hadoop fs -ls /out/mtc
	Found 2 items
	-rw-r--r--   3 zgg supergroup          0 2020-07-15 20:22 /out/mtc/_SUCCESS
	-rw-r--r--   3 zgg supergroup         48 2020-07-15 20:22 /out/mtc/part-r-00000.bz2
	
	[root@zgg ~]# bzip2 -d part-r-00000.bz2
	[root@zgg ~]# ls
	anaconda-ks.cfg  JavaCode.jar       part-r-00000  secondsort_test.txt  wc.txt
	groupdata.txt    partitiondata.txt  sample.txt    secondsort.txt
	[root@zgg ~]# cat part-r-00000 
	1949    111
	1950    22