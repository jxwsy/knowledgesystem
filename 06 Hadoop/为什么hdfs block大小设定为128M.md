# 为什么HDFS文件块（block）大小设定为128M

我们在HDFS中存储数据是以块（block）的形式存放在DataNode中的，
块（block）的大小可以通过设置dfs.blocksize来实现；

在Hadoop2.x的版本中，文件块的默认大小是128M，老版本中默认是64M；

## 一、寻址时间

寻址时间：HDFS中找到目标文件块（block）所需要的时间。

原理：

	文件块越大，寻址时间越短，但磁盘传输时间越长；

	文件块越小，寻址时间越长，但磁盘传输时间越短。


## 二、 HDFS中块（block）的大小为什么设置为128M？

1. HDFS中平均寻址时间大概为10ms；

2. 经过前人的大量测试发现，寻址时间为传输时间的1%时，为最佳状态；
所以最佳传输时间为10ms/0.01=1000ms=1s

3. 目前磁盘的传输速率普遍为100MB/s；

	计算出最佳block大小：100MB/s x 1s = 100MB

	所以我们设定block大小为128MB。
 

ps：实际在工业生产中，磁盘传输速率为200MB/s时，一般设定block大小为256MB

       磁盘传输速率为400MB/s时，一般设定block大小为512MB

原文链接：[一篇讲懂为什么HDFS文件块（block）大小设定为128M](https://blog.csdn.net/wx1528159409/article/details/84260023)