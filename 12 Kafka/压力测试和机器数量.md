# 压力测试和机器数量

[TOC]

## 1、压力测试

用 Kafka 官方自带的脚本，对 Kafka 进行压测。

Kafka 压测时，可以查看到哪个地方出现了瓶颈（CPU，内存，网络 IO）。一般都是网络 IO 达到瓶颈。

### 1.1、Kafka Producer 压力测试

（1）在/opt/module/kafka/bin 目录下面有这两个文件。

```sh
[atguigu@hadoop102 kafka]$ bin/kafka-producer-perf-test.sh --
topic test --record-size 100 --num-records 100000 --throughput 
-1 --producer-props 
bootstrap.servers=hadoop102:9092,hadoop103:9092,hadoop104:9092
```

说明：

- record-size 是一条信息有多大，单位是字节。
- num-records 是总共发送多少条信息。
- throughput 是每秒多少条信息，设成-1，表示不限流，可测出生产者最大吞吐量。

（2）Kafka 会打印下面的信息

	100000 records sent, 95877.277085 records/sec (9.14 MB/sec), 
	187.68 ms avg latency, 424.00 ms max latency, 155 ms 50th, 411 
	ms 95th, 423 ms 99th, 424 ms 99.9th.

参数解析：本例中一共写入 10w 条消息，吞吐量为 9.14 MB/sec，每次写入的平均延迟
为 187.68 毫秒，最大的延迟为 424.00 毫秒。

### 1.2、Kafka Consumer 压力测试

Consumer 的测试，如果这四个指标（IO，CPU，内存，网络）都不能改变，考虑增加分
区数来提升性能。

```sh
[atguigu@hadoop102 kafka]$ 
bin/kafka-consumer-perf-test.sh --zookeeper hadoop102:2181 --
topic test --fetch-size 10000 --messages 10000000 --threads 1
```

参数说明：
- --zookeeper 指定 zookeeper 的链接信息
- --topic 指定 topic 的名称
- --fetch-size 指定每次 fetch 的数据的大小
- --messages 总共要消费的消息个数

测试结果说明：

	start.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec
	2019-02-19 20:29:07:566, 2019-02-19 20:29:12:170, 9.5368, 2.0714, 100010, 21722.4153

开始测试时间，测试结束数据，共消费数据 9.5368MB，吞吐量 2.0714MB/s，共消费
100010 条，平均每秒消费 21722.4153 条。

## 2、机器数量计算

	Kafka 机器数量（经验公式）=2*（峰值生产速度*副本数/100）+1

先拿到峰值生产速度，再根据设定的副本数，就能预估出需要部署 Kafka 的数量。

比如我们的峰值生产速度是 50M/s，副本数为 2。Kafka 机器数量=2*（50*2/100）+ 1=3 台


原文地址：

[https://www.bilibili.com/video/BV1L4411K7hW?p=39](https://www.bilibili.com/video/BV1L4411K7hW?p=39)

[https://www.bilibili.com/video/BV1L4411K7hW?p=40](https://www.bilibili.com/video/BV1L4411K7hW?p=40)